Grounded generation and faithfulness in RAG

In Retrieval-Augmented Generation (RAG), the model should answer using retrieved evidence, not memorized or invented facts. Faithfulness means the answer statements are supported by citations to the evidence chunks.

Common failure modes:
- Hallucination: the model adds details not present in evidence.
- Mismatched citation: citations point to chunks that do not support the claim.
- Missing coverage: the answer ignores an important requirement in the rubric.

Ways to improve faithfulness:
- Use strong instructions: “Answer ONLY from evidence; if missing, say not enough evidence.”
- Re-rank candidates to bring the most relevant chunks to the top.
- Add a post-check that verifies key claims appear in the cited text.
- Evaluate with manual spot checks and automatic overlap/entailment heuristics.

A good grounded answer includes short, direct citations like [Chunk 2] and does not over-generalize beyond what the documents say.
