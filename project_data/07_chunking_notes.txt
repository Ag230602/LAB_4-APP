Chunking design notes (fixed vs semantic)

Fixed-size chunking splits text into windows (e.g., 1200 characters with overlap). It is simple and usually preserves retrieval recall because every piece of information appears somewhere.

Semantic chunking splits by meaning boundaries such as paragraphs or sections. It can improve precision because each chunk is more “about one thing,” but it can reduce recall if chunks become too small or if key context is separated.

In this project:
- Fixed chunk size: 1200 characters, overlap 200 characters.
- Semantic chunking: paragraphs merged until roughly 400–1200 characters.

Trade-off to watch:
- Smaller chunks improve retrieval specificity but increase the number of chunks (and computation).
- Larger chunks improve context for generation but can dilute similarity scores.
